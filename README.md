# Pulsar Candidate Identification Dataset (Object Detection Version)

This repository provides an object-detection version of the **pulsar candidate dataset** based on [HTRU1](https://github.com/as595/HTRU1) and [FAST](https://github.com/dzuwhf/FAST_label_data). The dataset is designed for training and evaluating deep learning modelsâ€”particularly YOLO-based modelsâ€”for automatic pulsar identification.

---

## ðŸ“‚ Dataset Description

The dataset consists of two key diagnostic subplots commonly used in pulsar candidate identification:

- **Subband plots** (phase vs frequency)
- **Subint plots** (phase vs time)

Each plot has been carefully cropped and verified, and is accompanied by a manually annotated label file (`.txt`) in YOLO-compatible format. These annotations indicate regions of interest containing pulsar signals.

---

## ðŸ“¥ Data Sources and References

- **HTRU1 Dataset**:  
  GitHub: [https://github.com/as595/HTRU1](https://github.com/as595/HTRU1)  
  Citation: *Morello et al. (2016), MNRAS, 463, 3, 3410â€“3423*  
  DOI: [10.1093/mnras/stw656](https://doi.org/10.1093/mnras/stw656)


- **FAST Dataset**:  
  GitHub: [https://github.com/dzuwhf/FAST_label_data](https://github.com/dzuwhf/FAST_label_data)  
  Citation: *Zhang et al. (2020), MNRAS, 495, 1, 195â€“202*  
  DOI: [10.1093/mnras/staa916](https://doi.org/10.1093/mnras/staa916)

---

## ðŸ“¦ Download Instructions

You can download the dataset from the **GitHub Releases** page:

ðŸ‘‰ [Download from Releases](https://github.com/YiningSongg/pulsar-object-detection-dataset)

Or via command-line using a helper script:

`bash download_data.sh`  

```bash
HTRU1/  
â”œâ”€â”€ HTRU1banddata/  
â”‚   â”œâ”€â”€ images/  
â”‚       â”œâ”€â”€ train/  
â”‚           â”œâ”€â”€ cand_000001.png  
â”‚           â”œâ”€â”€ ...  
â”‚           â”œâ”€â”€ pulsar_0000.png  
â”‚           â”œâ”€â”€ ...  
â”‚   â”œâ”€â”€ images/  
â”‚       â”œâ”€â”€ labels/  
â”‚           â”œâ”€â”€ pulsar_0000.txt
â”‚           â”œâ”€â”€ ...
â”œâ”€â”€ HTRU1intdata/
â”‚   â”œâ”€â”€ images/
â”‚       â”œâ”€â”€ train/
â”‚           â”œâ”€â”€ cand_000001.png
â”‚           â”œâ”€â”€ ...
â”‚           â”œâ”€â”€ pulsar_0000.png
â”‚           â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ images/
â”‚       â”œâ”€â”€ labels/
â”‚           â”œâ”€â”€ pulsar_0000.txt
â”‚           â”œâ”€â”€ ...
```

```bash
FAST/
â”œâ”€â”€ lables/
â”‚   â”œâ”€â”€ xxxxxx.txt
â”‚   â”œâ”€â”€ xxxxxx.txt
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ pulsar
â”‚       â”œâ”€â”€ xxxxxx.png
â”‚       â”œâ”€â”€ xxxxxx.png
â”‚   â”œâ”€â”€ rfi
â”‚       â”œâ”€â”€ xxxxxx.png
â”‚       â”œâ”€â”€ xxxxxx.png
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ pulsar
â”‚       â”œâ”€â”€ xxxxxx.png
â”‚       â”œâ”€â”€ xxxxxx.png
â”‚   â”œâ”€â”€ rfi
â”‚       â”œâ”€â”€ xxxxxx.png
â”‚       â”œâ”€â”€ xxxxxx.png
```

## ðŸš€ How to Use the Dataset

To train a model using **YOLOv8** (recommended version: `yolov8n` for lightweight applications), follow these steps:

### 1. Prepare Your Dataset Directory

Split the dataset into training, validation, and test folders according to your task needs and YOLOv8's requirement. 

### 2. Create the `data.yaml` File

The `data.yaml` file tells YOLOv8 where to find the dataset and how to interpret class labels. Here's an example:

```
yaml
path: path/to/your_dataset  # dataset root directory
train: images/train         # training images path
val: images/val             # validation images path
test: images/test           # test images path

# Class definitions
names:
  0: RFI
  1: pulsar
```

### 3. Train the YOLOv8 Model
To start training with YOLOv8 (using ultralytics CLI), Here's an example:

```
yolo task=detect mode=train model=yolov8n.pt data=data.yaml epochs=50 imgsz=640
```

### 4. Validate and Test
After training, validate the model or run inference on test images, Here's an example:

```
yolo task=detect mode=val model=runs/detect/train/weights/best.pt data=data.yaml
yolo task=detect mode=predict model=runs/detect/train/weights/best.pt source=images/test
```

## Suggestions for Further Optimization

Download and examine the original HTRU/FAST datasets to refine and verify the annotation quality.
Tune YOLOv8 hyperparameters (e.g., learning rate, image size, anchor size).
Explore using additional diagnostic plots or metadata (e.g., DM, S/N) as auxiliary inputs.
Consider using ensemble methods or transfer learning for better generalization.
